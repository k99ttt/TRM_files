{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRM\n",
    "Have you ever thought about automating repetitive tasks?\n",
    "so we have Task Recommender Machine (TRM) for you :)) \n",
    "\n",
    "thats powerd by reletivly big data and recurrent neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports as always \n",
    "import sys\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time sampling\n",
    "time sampling for a person that she started her job at 09/01/2022 and workin 9 hours a day with some taskes "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for time sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTimeSpace(string,start = '00:00:00'):\n",
    "    # string type is  \"%m/%d/%Y %H:%M:%S\"\n",
    "    start_minutes = datetime.strptime(start, '%H:%M:%S').minute + datetime.strptime(start, '%H:%M:%S').hour * 60\n",
    "    splited = string.split()\n",
    "    day = splited[0]\n",
    "    clock = splited[1]\n",
    "    splited = clock.split(':')\n",
    "    hour = splited[0]\n",
    "    minute = splited[1]\n",
    "    second = splited[2]\n",
    "    #score = 60 * (int(splited[0]) - datetime.strptime(start, '%H:%M:%S').hour ) + int(splited[1])\n",
    "    score = (60 * int(hour) + int(minute)) - start_minutes\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idGenerator(num):\n",
    "    bias = 1000\n",
    "    array = np.arange(0,num) + bias\n",
    "    array = array.astype(int)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock(string,worksPerDay = 9,start = '09:00:00',stop = '18:00:00'):\n",
    "    #-----------------------------------------------------------------\n",
    "    datetime_object = datetime.strptime(string, '%m/%d/%Y %H:%M:%S')\n",
    "    #-----------------------------------------------------------------\n",
    "    stop_minutes = datetime.strptime(stop, '%H:%M:%S').minute + datetime.strptime(stop, '%H:%M:%S').hour * 60\n",
    "    start_minutes = datetime.strptime(start, '%H:%M:%S').minute + datetime.strptime(start, '%H:%M:%S').hour * 60\n",
    "    #-----------------------------------------------------------------\n",
    "    rdn = random.randint(1,int((stop_minutes - start_minutes)/worksPerDay))\n",
    "    value = datetime_object + timedelta(minutes = rdn)\n",
    "    if value.hour >= datetime.strptime(stop, '%H:%M:%S').hour :\n",
    "        value = value - timedelta(minutes = value.minute)\n",
    "        value = value + timedelta(hours = 15)\n",
    "        datetime_object = value\n",
    "    else:\n",
    "       datetime_object = value\n",
    "       \n",
    "    if value.strftime('%a') =='Fri':\n",
    "        datetime_object = datetime_object - timedelta(minutes = value.minute)\n",
    "        datetime_object = datetime_object + timedelta(days = 1)   \n",
    "    #-----------------------------------------------------------------\n",
    "    return(datetime_object.strftime(\"%m/%d/%Y %H:%M:%S\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dictionary contains all paths(work's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'folder1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary contains all paths that you can add or remove \n",
    "dirs = {'/Desktop/folder9','/Desktop/folder8','/Desktop/folder1','/Desktop/folder2','/Desktop/folder3','/Desktop/folder4','/Desktop/folder5','/Desktop/folder6','/Desktop/data/folder7'}\n",
    "dirs = list(dirs)\n",
    "dirs[random.randint(0,len(dirs)-1)].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(persons,worksPerDay,lenOfData):\n",
    "    data = pd.DataFrame({'id': [0],'time' : [0],'log' : ['/']})\n",
    "    ids = iter(idGenerator(lenOfData))\n",
    "    #-----------------------------------------------------\n",
    "    for i in range(persons):\n",
    "        worksPerDay = int(np.random.normal(worksPerDay, 0.3, 1))\n",
    "        init = '09/01/2022 09:00:00'\n",
    "        thisId = next(ids)\n",
    "        df = pd.DataFrame({'id': thisId,'time' : [init],'log' : dirs[random.randint(0,len(dirs)-1)].split(\"/\")[-1]})\n",
    "        for j in range(int(lenOfData/persons)):\n",
    "            init = clock(init,worksPerDay)\n",
    "            df_new = pd.DataFrame({'id': thisId,'time' : [init],'log' : dirs[random.randint(0,len(dirs)-1)].split(\"/\")[-1]})\n",
    "            df = pd.concat([df,df_new], ignore_index = True)\n",
    "        data = pd.concat([data,df], ignore_index = True)\n",
    "    #-----------------------------------------------------\n",
    "    #dropping first row and re indexing\n",
    "    data.drop(index=(0),inplace=True)\n",
    "    data.index = data.index -1 \n",
    "\n",
    "    data.sort_values(by='time',inplace=True)\n",
    "    data.index = np.arange(0,len(data))\n",
    "    \n",
    "    for i in range(len(data) - lenOfData):\n",
    "        data.drop(index=(len(data)-1),inplace=True)\n",
    "    \n",
    "    #saving data to file in csv \n",
    "    data.to_csv('data.csv', index=True) \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1008</td>\n",
       "      <td>09/04/2022 14:30:00</td>\n",
       "      <td>folder8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1009</td>\n",
       "      <td>09/04/2022 14:40:00</td>\n",
       "      <td>folder7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1000</td>\n",
       "      <td>09/04/2022 14:45:00</td>\n",
       "      <td>folder6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1000</td>\n",
       "      <td>09/04/2022 14:51:00</td>\n",
       "      <td>folder9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1008</td>\n",
       "      <td>09/04/2022 14:52:00</td>\n",
       "      <td>folder3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                 time      log\n",
       "0    1000  09/01/2022 09:00:00  folder9\n",
       "1    1002  09/01/2022 09:00:00  folder8\n",
       "2    1003  09/01/2022 09:00:00  folder4\n",
       "3    1009  09/01/2022 09:00:00  folder6\n",
       "4    1005  09/01/2022 09:00:00  folder2\n",
       "..    ...                  ...      ...\n",
       "595  1008  09/04/2022 14:30:00  folder8\n",
       "596  1009  09/04/2022 14:40:00  folder7\n",
       "597  1000  09/04/2022 14:45:00  folder6\n",
       "598  1000  09/04/2022 14:51:00  folder9\n",
       "599  1008  09/04/2022 14:52:00  folder3\n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#runing sampling code and write it's return to CSV\n",
    "sampling(persons = 10,worksPerDay = 12,lenOfData = 600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no time base data for TRM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the time of doing the work is not important, the order of doing the work is important In such a way that any work is recommended immediately after the previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1009</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>09/01/2022 09:00:00</td>\n",
       "      <td>folder2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1008</td>\n",
       "      <td>09/04/2022 14:30:00</td>\n",
       "      <td>folder8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1009</td>\n",
       "      <td>09/04/2022 14:40:00</td>\n",
       "      <td>folder7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1000</td>\n",
       "      <td>09/04/2022 14:45:00</td>\n",
       "      <td>folder6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1000</td>\n",
       "      <td>09/04/2022 14:51:00</td>\n",
       "      <td>folder9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1008</td>\n",
       "      <td>09/04/2022 14:52:00</td>\n",
       "      <td>folder3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                 time      log\n",
       "0    1000  09/01/2022 09:00:00  folder9\n",
       "1    1002  09/01/2022 09:00:00  folder8\n",
       "2    1003  09/01/2022 09:00:00  folder4\n",
       "3    1009  09/01/2022 09:00:00  folder6\n",
       "4    1005  09/01/2022 09:00:00  folder2\n",
       "..    ...                  ...      ...\n",
       "595  1008  09/04/2022 14:30:00  folder8\n",
       "596  1009  09/04/2022 14:40:00  folder7\n",
       "597  1000  09/04/2022 14:45:00  folder6\n",
       "598  1000  09/04/2022 14:51:00  folder9\n",
       "599  1008  09/04/2022 14:52:00  folder3\n",
       "\n",
       "[600 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data from CSV\n",
    "data = pd.read_csv('data.csv') \n",
    "data.drop(columns=('Unnamed: 0'),inplace=True)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeFormater(string):\n",
    "    # remove '[' and %d/%b/%Y:%H:%M:%S to %m/%d/%Y %H:%M:%S string to string\n",
    "    try:\n",
    "        string = string.replace('[', '')\n",
    "        stringToDate = datetime.strptime(string, \"%d/%b/%Y:%H:%M:%S\")\n",
    "        string = stringToDate.strftime('%m/%d/%Y %H:%M:%S')\n",
    "        return string\n",
    "    except:\n",
    "        return '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTimeStamp(string):\n",
    "    return time.mktime(datetime.strptime(string,\"%m/%d/%Y %H:%M:%S\").timetuple())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/07/2017 23:59:19</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/07/2017 23:59:19</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>11/08/2017 00:39:07</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>11/08/2017 00:39:07</td>\n",
       "      <td>GET /login.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>11/08/2017 00:39:07</td>\n",
       "      <td>GET /login.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:12</td>\n",
       "      <td>GET /showcode.php?id=309&amp;nm=ham05 HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:23</td>\n",
       "      <td>GET /allsubmission.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15786</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:32</td>\n",
       "      <td>GET /showcode.php?id=309&amp;nm=ham05 HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:35</td>\n",
       "      <td>GET /allsubmission.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:46</td>\n",
       "      <td>GET /home.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15789 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                 time  \\\n",
       "0      10.130.2.1  11/07/2017 23:59:19   \n",
       "1      10.130.2.1  11/07/2017 23:59:19   \n",
       "2      10.129.2.1  11/08/2017 00:39:07   \n",
       "3      10.129.2.1  11/08/2017 00:39:07   \n",
       "4      10.129.2.1  11/08/2017 00:39:07   \n",
       "...           ...                  ...   \n",
       "15784  10.130.2.1  03/02/2018 15:47:12   \n",
       "15785  10.130.2.1  03/02/2018 15:47:23   \n",
       "15786  10.130.2.1  03/02/2018 15:47:32   \n",
       "15787  10.130.2.1  03/02/2018 15:47:35   \n",
       "15788  10.130.2.1  03/02/2018 15:47:46   \n",
       "\n",
       "                                              log  \n",
       "0                                  GET / HTTP/1.1  \n",
       "1                                  GET / HTTP/1.1  \n",
       "2                                  GET / HTTP/1.1  \n",
       "3                         GET /login.php HTTP/1.1  \n",
       "4                         GET /login.php HTTP/1.1  \n",
       "...                                           ...  \n",
       "15784  GET /showcode.php?id=309&nm=ham05 HTTP/1.1  \n",
       "15785             GET /allsubmission.php HTTP/1.1  \n",
       "15786  GET /showcode.php?id=309&nm=ham05 HTTP/1.1  \n",
       "15787             GET /allsubmission.php HTTP/1.1  \n",
       "15788                      GET /home.php HTTP/1.1  \n",
       "\n",
       "[15789 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('weblog.csv')  #loading dataset\n",
    "data.rename(columns={\"URL\": \"log\", \"IP\": \"id\",\"Time\": \"time\"},inplace=True) \n",
    "data.drop(['Staus'], axis=1,inplace=True) # we dont need that right now !\n",
    "#------------------------------------------------------------------------\n",
    "shouldRemove = data['id'].value_counts()[data['id'].value_counts() < 100] #removing Chert!! ids :))\n",
    "for i in range(len(shouldRemove)):\n",
    "    data.drop(data.loc[data['id'] == shouldRemove.index[i]].index,inplace=True)# it Automaticly delete's time missing values\n",
    "#------------------------------------------------------------------------\n",
    "data['time'] = data ['time'].apply(timeFormater) #changing time format to smother one\n",
    "data['timestamp'] = data ['time'].apply(toTimeStamp) #time stamp for best sorting by time\n",
    "data.sort_values(by='timestamp',ascending=True,inplace=True) #sorting by time\n",
    "data.drop(['timestamp'], axis=1,inplace=True) #removing time stamp , we dont need that anymore !\n",
    "#------------------------------------------------------------------------\n",
    "data.reset_index(inplace=True) #reset index \n",
    "data.drop(['index'], axis=1,inplace=True)#remove old index \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11/07/2017 23:59:19'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startDate = data.loc[0]['time']\n",
    "startDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/07/2017 23:59:19</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/07/2017 23:59:19</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/08/2017 05:01:24</td>\n",
       "      <td>GET /login.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/08/2017 05:01:24</td>\n",
       "      <td>GET /login.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/08/2017 15:56:23</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:12</td>\n",
       "      <td>GET /showcode.php?id=309&amp;nm=ham05 HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:23</td>\n",
       "      <td>GET /allsubmission.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15786</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:32</td>\n",
       "      <td>GET /showcode.php?id=309&amp;nm=ham05 HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:35</td>\n",
       "      <td>GET /allsubmission.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:46</td>\n",
       "      <td>GET /home.php HTTP/1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4056 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                 time  \\\n",
       "0      10.130.2.1  11/07/2017 23:59:19   \n",
       "1      10.130.2.1  11/07/2017 23:59:19   \n",
       "16     10.130.2.1  11/08/2017 05:01:24   \n",
       "17     10.130.2.1  11/08/2017 05:01:24   \n",
       "50     10.130.2.1  11/08/2017 15:56:23   \n",
       "...           ...                  ...   \n",
       "15784  10.130.2.1  03/02/2018 15:47:12   \n",
       "15785  10.130.2.1  03/02/2018 15:47:23   \n",
       "15786  10.130.2.1  03/02/2018 15:47:32   \n",
       "15787  10.130.2.1  03/02/2018 15:47:35   \n",
       "15788  10.130.2.1  03/02/2018 15:47:46   \n",
       "\n",
       "                                              log  \n",
       "0                                  GET / HTTP/1.1  \n",
       "1                                  GET / HTTP/1.1  \n",
       "16                        GET /login.php HTTP/1.1  \n",
       "17                        GET /login.php HTTP/1.1  \n",
       "50                                 GET / HTTP/1.1  \n",
       "...                                           ...  \n",
       "15784  GET /showcode.php?id=309&nm=ham05 HTTP/1.1  \n",
       "15785             GET /allsubmission.php HTTP/1.1  \n",
       "15786  GET /showcode.php?id=309&nm=ham05 HTTP/1.1  \n",
       "15787             GET /allsubmission.php HTTP/1.1  \n",
       "15788                      GET /home.php HTTP/1.1  \n",
       "\n",
       "[4056 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['id'] == '10.130.2.1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDays(date,startDate='11/07/2017 9:00:00'):\n",
    "    #it takes a date and give us how many mitunes away from everyday starting date \n",
    "    date = datetime.strptime(date, '%m/%d/%Y %H:%M:%S')\n",
    "    startDate = datetime.strptime(startDate, '%m/%d/%Y %H:%M:%S')\n",
    "    return (date.year - startDate.year) * 366 + (date.month - startDate.month) * 31 + (date.day - startDate.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekDay(datetime_str):\n",
    "    #it takes a date and give us weekDay! like Mon,Thu,Wed\n",
    "    date = datetime.strptime(datetime_str, '%m/%d/%Y %H:%M:%S')\n",
    "    return date.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toDays('11/09/2017 23:59:19')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>log</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>timeSerious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/07/2017 23:59:19</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>11/07/2017 23:59:19</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>11/08/2017 00:39:07</td>\n",
       "      <td>GET / HTTP/1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>11/08/2017 00:39:07</td>\n",
       "      <td>GET /login.php HTTP/1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>11/08/2017 00:39:07</td>\n",
       "      <td>GET /login.php HTTP/1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wed</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:12</td>\n",
       "      <td>GET /showcode.php?id=309&amp;nm=ham05 HTTP/1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>Fri</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:23</td>\n",
       "      <td>GET /allsubmission.php HTTP/1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>Fri</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15786</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:32</td>\n",
       "      <td>GET /showcode.php?id=309&amp;nm=ham05 HTTP/1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>Fri</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:35</td>\n",
       "      <td>GET /allsubmission.php HTTP/1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>Fri</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>03/02/2018 15:47:46</td>\n",
       "      <td>GET /home.php HTTP/1.1</td>\n",
       "      <td>56</td>\n",
       "      <td>Fri</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15789 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                 time  \\\n",
       "0      10.130.2.1  11/07/2017 23:59:19   \n",
       "1      10.130.2.1  11/07/2017 23:59:19   \n",
       "2      10.129.2.1  11/08/2017 00:39:07   \n",
       "3      10.129.2.1  11/08/2017 00:39:07   \n",
       "4      10.129.2.1  11/08/2017 00:39:07   \n",
       "...           ...                  ...   \n",
       "15784  10.130.2.1  03/02/2018 15:47:12   \n",
       "15785  10.130.2.1  03/02/2018 15:47:23   \n",
       "15786  10.130.2.1  03/02/2018 15:47:32   \n",
       "15787  10.130.2.1  03/02/2018 15:47:35   \n",
       "15788  10.130.2.1  03/02/2018 15:47:46   \n",
       "\n",
       "                                              log  day weekday  timeSerious  \n",
       "0                                  GET / HTTP/1.1    0     Tue         1439  \n",
       "1                                  GET / HTTP/1.1    0     Tue         1439  \n",
       "2                                  GET / HTTP/1.1    1     Wed           39  \n",
       "3                         GET /login.php HTTP/1.1    1     Wed           39  \n",
       "4                         GET /login.php HTTP/1.1    1     Wed           39  \n",
       "...                                           ...  ...     ...          ...  \n",
       "15784  GET /showcode.php?id=309&nm=ham05 HTTP/1.1   56     Fri          947  \n",
       "15785             GET /allsubmission.php HTTP/1.1   56     Fri          947  \n",
       "15786  GET /showcode.php?id=309&nm=ham05 HTTP/1.1   56     Fri          947  \n",
       "15787             GET /allsubmission.php HTTP/1.1   56     Fri          947  \n",
       "15788                      GET /home.php HTTP/1.1   56     Fri          947  \n",
       "\n",
       "[15789 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TimeSerious feature\n",
    "dayArray = data['time'].apply(toDays)\n",
    "uniqueDayArray = np.array(dayArray.unique())\n",
    "asignedArray = np.arange(0,len(uniqueDayArray))\n",
    "for i in range(len(uniqueDayArray)):\n",
    "        dayArray[dayArray == uniqueDayArray[i]] = asignedArray[i]\n",
    "data['day'] = dayArray\n",
    "#-----------------------------------------------------\n",
    "#it takes a date and give us weekDay! like Mon,Thu,Wed\n",
    "data['weekday'] = data ['time'].apply(weekDay) \n",
    "#-----------------------------------------------------\n",
    "data['timeSerious'] = data ['time'].apply(toTimeSpace)\n",
    "#-----------------------------------------------------\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['timeSerious'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['timeSerious'].max() #1439 minuts is about 23:59 past from 00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorkToNum feature\n",
    "allWorks = np.array(data['log'].unique())\n",
    "#-----------------------------------------------------\n",
    "rangeVector = np.arange(1,len(allWorks)+1)\n",
    "#-----------------------------------------------------\n",
    "dictionary = {}\n",
    "for i in range(len(allWorks)):\n",
    "    dictionary[allWorks[i]] = rangeVector[i]\n",
    "#-----------------------------------------------------\n",
    "def workToNum(string):\n",
    "    return dictionary[string]\n",
    "#-----------------------------------------------------\n",
    "data['workToNum'] = data['log'].apply(workToNum)\n",
    "#-----------------------------------------------------\n",
    "data.drop('log', axis='columns',inplace=True)\n",
    "data.drop('time', axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WeekToNum feature\n",
    "allWeeks = np.array(data['weekday'].unique())\n",
    "#-----------------------------------------------------\n",
    "rangeVector = np.arange(1,len(allWeeks)+1)\n",
    "#-----------------------------------------------------\n",
    "WeeksDictionary = {}\n",
    "for i in range(len(allWeeks)):\n",
    "    WeeksDictionary[allWeeks[i]] = rangeVector[i]\n",
    "#-----------------------------------------------------\n",
    "def weekToNum(string):\n",
    "    return WeeksDictionary[string]\n",
    "#-----------------------------------------------------\n",
    "data['weekToNum'] = data['weekday'].apply(weekToNum)\n",
    "data.drop('weekday', axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>timeSerious</th>\n",
       "      <th>workToNum</th>\n",
       "      <th>weekToNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9351</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1217</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1217</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1217</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9363</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1217</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9364</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1217</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14425</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1256</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14434</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1256</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14435</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1256</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14436</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1256</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14437</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>40</td>\n",
       "      <td>1256</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1626 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  day  timeSerious  workToNum  weekToNum\n",
       "9351   10.130.2.1   40         1217          7          7\n",
       "9353   10.130.2.1   40         1217          2          7\n",
       "9354   10.130.2.1   40         1217         10          7\n",
       "9363   10.130.2.1   40         1217          7          7\n",
       "9364   10.130.2.1   40         1217          7          7\n",
       "...           ...  ...          ...        ...        ...\n",
       "14425  10.130.2.1   40         1256          2          7\n",
       "14434  10.130.2.1   40         1256          7          7\n",
       "14435  10.130.2.1   40         1256          2          7\n",
       "14436  10.130.2.1   40         1256          7          7\n",
       "14437  10.130.2.1   40         1256          2          7\n",
       "\n",
       "[1626 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = data.loc[data['id']=='10.130.2.1']\n",
    "d.loc[d['day'] == 40]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analyst tools make data even more appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTimeLine(id = '10.130.2.1' , day= 21):\n",
    "    d = data.loc[data['id']==id]\n",
    "    arr = d.loc[d['day'] == day]['timeSerious'].to_numpy()\n",
    "    unique, counts = np.unique(arr, return_counts=True)\n",
    "    mass = np.arange(0,1440)\n",
    "    lineSpace = np.zeros((1440))\n",
    "    lineSpace[unique] = counts\n",
    "    fig = plt.figure(figsize = (25, 10))\n",
    "    # creating the bar plot\n",
    "    plt.bar(mass, lineSpace, color ='red',width = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>timeSerious</th>\n",
       "      <th>workToNum</th>\n",
       "      <th>weekToNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15786</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15789 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  day  timeSerious  workToNum  weekToNum\n",
       "0      10.130.2.1    0         1439          1          1\n",
       "1      10.130.2.1    0         1439          1          1\n",
       "2      10.129.2.1    1           39          1          2\n",
       "3      10.129.2.1    1           39          2          2\n",
       "4      10.129.2.1    1           39          2          2\n",
       "...           ...  ...          ...        ...        ...\n",
       "15784  10.130.2.1   56          947        292          4\n",
       "15785  10.130.2.1   56          947         25          4\n",
       "15786  10.130.2.1   56          947        292          4\n",
       "15787  10.130.2.1   56          947         25          4\n",
       "15788  10.130.2.1   56          947          7          4\n",
       "\n",
       "[15789 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: day, dtype: int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['id']=='10.131.1.1']['day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotTimeLine(id = '10.131.2.1',day= 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotTimeLine(id = '10.131.2.1',day= 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems that you should delete days 40th and 21th for id :'10.130.2.1' !!\n",
    "data.drop(data.loc[(data['id']=='10.130.2.1')&(data['day']==40)].index,inplace=True)\n",
    "data.drop(data.loc[(data['id']=='10.130.2.1')&(data['day']==21)].index,inplace=True)\n",
    "# it seems that you should delete day 21th for id :'10.129.2.1' !!\n",
    "data.drop(data.loc[(data['id']=='10.129.2.1')&(data['day']==21)].index,inplace=True)\n",
    "# it seems that you should delete days 40th and 21th for id :'10.128.2.1' !!\n",
    "data.drop(data.loc[(data['id']=='10.128.2.1')&(data['day']==40)].index,inplace=True)\n",
    "data.drop(data.loc[(data['id']=='10.128.2.1')&(data['day']==21)].index,inplace=True)\n",
    "# it seems that you should delete days 40th and 21th for id :'10.128.2.1' !!\n",
    "data.drop(data.loc[(data['id']=='10.128.2.1')&(data['day']==40)].index,inplace=True)\n",
    "data.drop(data.loc[(data['id']=='10.128.2.1')&(data['day']==21)].index,inplace=True)\n",
    "# it seems that you should delete days 40th and 21th for id :'10.128.2.1' !!\n",
    "data.drop(data.loc[(data['id']=='10.131.0.1')&(data['day']==40)].index,inplace=True)\n",
    "data.drop(data.loc[(data['id']=='10.131.0.1')&(data['day']==21)].index,inplace=True)\n",
    "# it seems that you should delete day 21th for id :'10.129.2.1' !!\n",
    "data.drop(data.loc[(data['id']=='10.131.2.1')&(data['day']==21)].index,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Frame to numpy matrix for training data\n",
    "that's achive four parameters: <br>\n",
    "1 - number of all persons (unique ids) <br>\n",
    "2 - number of data's (diffrent days) of each persons <br>\n",
    "3 - number of all possible works (len of workToVec) <br>\n",
    "4 - maximum of number of works in all days <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding functions\n",
    "make a padding to np arrays for instance: <br>\n",
    "maxlen = 4 <br>\n",
    "array = [2,3] <br>\n",
    "new array = [2,3,0,0] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorPadding(array,maxlen):\n",
    "    newArray = np.zeros((1,maxlen))\n",
    "    newArray = newArray[0]\n",
    "    newArray[0:len(array)] = array\n",
    "    newArray = newArray.astype(int)\n",
    "    return newArray"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onehot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecToOneHot(vec,max):\n",
    "    oh = np.zeros((vec.size, max))\n",
    "    oh[np.arange(vec.size), vec] = 1\n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matToOneHot(vec,type = 'work'):\n",
    "    numberOfVecs = vec.shape[0] #number of vectors\n",
    "    lenOfVecs = vec.shape[1] #len of each vector\n",
    "     # len of onehot matrix\n",
    "    if type =='week':\n",
    "        lenOfOh = 8 # correspond to 7 days of week + 1 for null days\n",
    "    else :  \n",
    "        lenOfOh = vec.max() + 1  \n",
    "    #---------------------------------------------\n",
    "    mat = np.zeros((lenOfVecs,lenOfOh)) # matrix !\n",
    "    #---------------------------------------------\n",
    "    for n in range(numberOfVecs):\n",
    "        mat = np.concatenate((mat,vecToOneHot(vec[n] ,lenOfOh)))\n",
    "        #-----------------------------------------\n",
    "    mat = mat[lenOfVecs:]\n",
    "    mat = mat.reshape(numberOfVecs,lenOfVecs,lenOfOh)\n",
    "    return mat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all together and Saving Data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RnnWorkDataOH.shape => (55, 95, 293)\n",
      "RnnWeekDataOH.shape => (55, 95, 8)\n",
      "saved as RnnWorkData_id:10.130.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.130.2.1.npy\n",
      "=======================================\n",
      "RnnWorkDataOH.shape => (23, 124, 244)\n",
      "RnnWeekDataOH.shape => (23, 124, 8)\n",
      "saved as RnnWorkData_id:10.129.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.129.2.1.npy\n",
      "=======================================\n",
      "RnnWorkDataOH.shape => (54, 106, 292)\n",
      "RnnWeekDataOH.shape => (54, 106, 8)\n",
      "saved as RnnWorkData_id:10.128.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.128.2.1.npy\n",
      "=======================================\n",
      "RnnWorkDataOH.shape => (54, 117, 289)\n",
      "RnnWeekDataOH.shape => (54, 117, 8)\n",
      "saved as RnnWorkData_id:10.131.0.1.npy\n",
      "saved as RnnWeekDataOH_id:10.131.0.1.npy\n",
      "=======================================\n",
      "RnnWorkDataOH.shape => (23, 161, 243)\n",
      "RnnWeekDataOH.shape => (23, 161, 8)\n",
      "saved as RnnWorkData_id:10.131.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.131.2.1.npy\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "Persons = data['id'].unique() # array of all unique ids in other hand array of all diffrent persons\n",
    "lenPersons = len(data['id'].unique()) # number of all unique ids in other hand number of all diffrent persons\n",
    "workToNumLen = max(data['workToNum']) #number of all possible works\n",
    "#------------------------------------------------------------------\n",
    "for idx in range(lenPersons):\n",
    "    currentId = Persons[idx]\n",
    "    numOfDays = len(data.loc[data['id'] == currentId]['day'].unique()) # number of days that one person have in other hands #of All training data for one person\n",
    "    days = data.loc[data['id'] == currentId]['day'].unique()\n",
    "    inputSize = max(data.loc[data['id'] == currentId]['day'].value_counts())#inputSize is size of architecture of # of RNN blocks (maximum of number of works in all days)\n",
    "    #--------------------------------------------------------------\n",
    "    RnnWorkData = np.zeros((numOfDays,inputSize))\n",
    "    RnnWeekData = np.zeros((numOfDays,inputSize))\n",
    "    #--------------------------------------------------------------\n",
    "    for i in range(len(days)):\n",
    "        temp = data.loc[(data['id'] == currentId) & (data['day'] == days[i])] \n",
    "        workToNumVector = temp['workToNum'].to_numpy()\n",
    "        workToNumVector = vectorPadding(workToNumVector,inputSize)\n",
    "        weekToNumVector = temp['weekToNum'].to_numpy()\n",
    "        weekToNumVector  = vectorPadding(weekToNumVector,inputSize)\n",
    "        #----------------------------------------------------------\n",
    "        RnnWorkData[i,:] = workToNumVector\n",
    "        RnnWeekData[i,:] = weekToNumVector\n",
    "        #print(workToNumVector)            # do not Delete!!\n",
    "    #--------------------------------------------------------------\n",
    "    RnnWorkDataOH = matToOneHot(RnnWorkData.astype(int)) # transforming scalar numbers to onehot\n",
    "    RnnWeekDataOH = matToOneHot(RnnWeekData.astype(int),type='week') # transforming scalar numbers to onehot\n",
    "    #--------------------------------------------------------------\n",
    "    print('RnnWorkDataOH.shape => ' +str(RnnWorkDataOH.shape))\n",
    "    print('RnnWeekDataOH.shape => ' +str(RnnWeekDataOH.shape))\n",
    "    #--------------------------------------------------------------\n",
    "    #print('RnnWorkData =>')               # do not Delete!!\n",
    "    #print(RnnWorkData.astype(int))        # do not Delete!!\n",
    "    #--------------------------------------------------------------\n",
    "    #print('matToOneHot(RnnWorkData) =>')  # do not Delete!!\n",
    "    #print(RnnWorkDataOH )                 # do not Delete!!\n",
    "    #--------------------------------------------------------------\n",
    "    #print('RnnWeekData =>')               # do not Delete!! \n",
    "    #print(RnnWeekData.astype(int))        # do not Delete!!\n",
    "    #--------------------------------------------------------------\n",
    "    #print('matToOneHot(RnnWeekData) =>')  # do not Delete!!\n",
    "    #print(RnnWeekDataOH )                 # do not Delete!!\n",
    "    #--------------------------------------------------------------\n",
    "    with open('data/no_time_base/RnnWorkDataOH_id:'+str(currentId)+'.npy', 'wb') as f:\n",
    "        np.save(f,RnnWorkDataOH)\n",
    "    print('saved as '+'RnnWorkData_id:'+str(currentId)+'.npy')    \n",
    "    with open('data/no_time_base/RnnWeekDataOH_id:'+str(currentId)+'.npy', 'wb') as f:\n",
    "        np.save(f,RnnWeekDataOH)\n",
    "    print('saved as '+'RnnWeekDataOH_id:'+str(currentId)+'.npy')   \n",
    "    print('=======================================')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Rnn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PersonId = '10.130.2.1'\n",
    "with open('data/no_time_base/RnnWorkDataOH_id:'+str(PersonId)+'.npy', 'rb') as f:\n",
    "    RnnWorkDataOH = np.load(f)\n",
    "    X = RnnWorkDataOH\n",
    "with open('data/no_time_base/RnnWeekDataOH_id:'+str(PersonId)+'.npy', 'rb') as f:\n",
    "    RnnWeekDataOH = np.load(f)\n",
    "#print('RnnWorkDataOH:')    \n",
    "#print(RnnWorkDataOH)\n",
    "#print('RnnWeekDataOH:')\n",
    "#print(RnnWeekDataOH)\n",
    "# we decided to use no_time_base data ro id:# we decided to use no_time_base data ro id:10.130.2.1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time base data for TRM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, in addition to the order of doing things, the time of doing things is also important\n",
    "In such a way that any work is not recommended immediately after the previous work and waits until its time comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>timeSerious</th>\n",
       "      <th>workToNum</th>\n",
       "      <th>weekToNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1439</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.129.2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15786</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>10.130.2.1</td>\n",
       "      <td>56</td>\n",
       "      <td>947</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7706 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  day  timeSerious  workToNum  weekToNum\n",
       "0      10.130.2.1    0         1439          1          1\n",
       "1      10.130.2.1    0         1439          1          1\n",
       "2      10.129.2.1    1           39          1          2\n",
       "3      10.129.2.1    1           39          2          2\n",
       "4      10.129.2.1    1           39          2          2\n",
       "...           ...  ...          ...        ...        ...\n",
       "15784  10.130.2.1   56          947        292          4\n",
       "15785  10.130.2.1   56          947         25          4\n",
       "15786  10.130.2.1   56          947        292          4\n",
       "15787  10.130.2.1   56          947         25          4\n",
       "15788  10.130.2.1   56          947          7          4\n",
       "\n",
       "[7706 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotData = data['timeSerious'].value_counts()\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "xPlot = np.array(plotData.index)\n",
    "yPlot = np.array(plotData.values)\n",
    "plt.bar(xPlot,yPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RnnWorkDataOH.shape => (55, 1440, 290)\n",
      "RnnWeekDataOH.shape => (55, 1440, 8)\n",
      "saved as RnnWorkData_id:10.130.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.130.2.1.npy\n",
      "==================================\n",
      "RnnWorkDataOH.shape => (23, 1440, 244)\n",
      "RnnWeekDataOH.shape => (23, 1440, 8)\n",
      "saved as RnnWorkData_id:10.129.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.129.2.1.npy\n",
      "==================================\n",
      "RnnWorkDataOH.shape => (54, 1440, 291)\n",
      "RnnWeekDataOH.shape => (54, 1440, 8)\n",
      "saved as RnnWorkData_id:10.128.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.128.2.1.npy\n",
      "==================================\n",
      "RnnWorkDataOH.shape => (54, 1440, 288)\n",
      "RnnWeekDataOH.shape => (54, 1440, 8)\n",
      "saved as RnnWorkData_id:10.131.0.1.npy\n",
      "saved as RnnWeekDataOH_id:10.131.0.1.npy\n",
      "==================================\n",
      "RnnWorkDataOH.shape => (23, 1440, 234)\n",
      "RnnWeekDataOH.shape => (23, 1440, 8)\n",
      "saved as RnnWorkData_id:10.131.2.1.npy\n",
      "saved as RnnWeekDataOH_id:10.131.2.1.npy\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "rnnSize = 541 #  = 9 * 60 + 1 , 540 minutes work for everyday \n",
    "rnnSize = 1440 \n",
    "Persons = data['id'].unique() # array of all unique ids in other hand array of all diffrent persons\n",
    "lenPersons = len(data['id'].unique()) # number of all unique ids in other hand number of all diffrent persons\n",
    "#------------------------------------------------------------------\n",
    "for idx in range(lenPersons):\n",
    "   currentId = Persons[idx]\n",
    "   numOfDays = len(data.loc[data['id'] == currentId]['day'].unique()) # #of days that one person have in other hands #of All training data for one person\n",
    "   days = data.loc[data['id'] == currentId]['day'].unique()\n",
    "   RnnWorkData = np.zeros((numOfDays,rnnSize),dtype=(int))\n",
    "   RnnWeekData = np.zeros((numOfDays,rnnSize),dtype=(int))\n",
    "   for i in range(len(days)):\n",
    "         #Works : \n",
    "         oneDayRnnWorkData = np.zeros((rnnSize),dtype=int)\n",
    "         temp = data.loc[(data['id'] == currentId) & (data['day'] == days[i])] \n",
    "         workIdx = temp[['timeSerious','workToNum']].to_numpy().T[0]\n",
    "         workValue = temp[['timeSerious','workToNum']].to_numpy().T[1]\n",
    "         oneDayRnnWorkData[workIdx] = workValue\n",
    "         #Weeks :\n",
    "         oneDayRnnWeekData = np.zeros((rnnSize),dtype=int)\n",
    "         temp = data.loc[(data['id'] == currentId) & (data['day'] == days[i])] \n",
    "         weekIdx = temp[['timeSerious','weekToNum']].to_numpy().T[0]\n",
    "         weekValue = temp[['timeSerious','weekToNum']].to_numpy().T[1]\n",
    "         oneDayRnnWeekData[weekIdx] = weekValue\n",
    "         #------------------------------------------------------------------\n",
    "         #now adding every single days to RnnWorkData\n",
    "         #Works :\n",
    "         RnnWorkData[i,:] = oneDayRnnWorkData\n",
    "         #Weeks :\n",
    "         RnnWeekData[i,:] = oneDayRnnWeekData\n",
    "         #------------------------------------------------------------------\n",
    "         #Works :\n",
    "         #print(workIdx)                                  # do not Delete!!\n",
    "         #print(workValue)                                # do not Delete!!\n",
    "         #print(oneDayRnnWorkData)                        # do not Delete!!\n",
    "         #Weeks :\n",
    "         #print(weekIdx)                                  # do not Delete!!\n",
    "         #print(weekValue)                                # do not Delete!!\n",
    "         #print(oneDayRnnWeekData)                        # do not Delete!!\n",
    "         #------------------------------------------------------------------\n",
    "   #now make them onehot from scaler      \n",
    "   #Works :        \n",
    "   RnnWorkDataOH = matToOneHot(RnnWorkData)\n",
    "   #Weeks :\n",
    "   RnnWeekDataOH = matToOneHot(RnnWeekData,type='week')\n",
    "   #--------------------------------------------------------------------------\n",
    "   #Work :\n",
    "   print('RnnWorkDataOH.shape => '+str(RnnWorkDataOH.shape))    \n",
    "   #print(RnnWorkDataOH[1][1])                              # do not Delete!!\n",
    "   #Week :\n",
    "   print('RnnWeekDataOH.shape => '+str(RnnWeekDataOH.shape))    \n",
    "   #print(RnnWeekDataOH[1][2])                              # do not Delete!!\n",
    "   #--------------------------------------------------------------------------\n",
    "   with open('data/time_base/RnnWorkDataOH_id:'+str(currentId)+'.npy', 'wb') as f:\n",
    "      np.save(f,RnnWorkDataOH)\n",
    "   print('saved as '+'RnnWorkData_id:'+str(currentId)+'.npy')    \n",
    "   with open('data/time_base/RnnWeekDataOH_id:'+str(currentId)+'.npy', 'wb') as f:\n",
    "      np.save(f,RnnWeekDataOH)\n",
    "   print('saved as '+'RnnWeekDataOH_id:'+str(currentId)+'.npy') \n",
    "   print('==================================')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Rnn Data\n",
    "Load data from saved , generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RnnWorkDataOH:\n",
      "(3, 541, 10)\n"
     ]
    }
   ],
   "source": [
    "PersonId = 1000\n",
    "with open('data/time_base/RnnWorkDataOH_id:'+str(PersonId)+'.npy', 'rb') as f:\n",
    "    RnnWorkDataOH = np.load(f)\n",
    "with open('data/time_base/RnnWeekDataOH_id:'+str(PersonId)+'.npy', 'rb') as f:\n",
    "    RnnWeekDataOH = np.load(f)\n",
    "print('RnnWorkDataOH:')    \n",
    "print(RnnWorkDataOH.shape)\n",
    "#print('RnnWeekDataOH:')\n",
    "#print(RnnWeekDataOH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switchable TRM !! STRM in short\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is switchable TRM? remebmer no_time base and time base TRM.\n",
    "in this phase we want to switch between them !!\n",
    "but how? we can take users feedback as a data and feed to RNN to learn in wich situations we need no time base or time base model !! for example Some habits that are done at a specific time are unfortunately the result of procrastinating for example a person is used to doing one thing at a time, and if we suggest her to do that thing earlier, it might be in her favor But sometimes we may suggest something to the user that she may not want to do because she wants to rest at that time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRM data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fakeReccomendedSequance(numOfDays = 5,jobsPerADay = 8,currentId = 1000, maxOfWorks = 10): # sampling of recommendation of no time base TRM\n",
    "    m = numOfDays\n",
    "    tx = jobsPerADay\n",
    "    tx = int(np.random.normal(tx,0.3,1))\n",
    "    tmax = maxOfWorks\n",
    "    Xoh = len(dictionary)\n",
    "    x = np.zeros((m,tmax,Xoh))\n",
    "    y = np.zeros((m,tmax,1))\n",
    "    for j in range(m):\n",
    "        for i in range(tx):\n",
    "            randIdx = random.randint(0,len(dictionary)-1)\n",
    "            vec = vecToOneHot(np.array([randIdx]),len(dictionary))\n",
    "            x[j,i,:] = vec \n",
    "            #---------------------------------------------------------------------\n",
    "            label = np.random.choice([0,1], 1, p=[0.7,0.3]) # weighted random , because number of acceptation is less\n",
    "            y[j,i,:] = label\n",
    "            #---------------------------------------------------------------------\n",
    "    print('X.shape => '+str(x.shape))     \n",
    "    print('Y.shape => '+str(y.shape))        \n",
    "    with open('data/switch/switchRnnXData_id:'+str(currentId)+'.npy', 'wb') as f:\n",
    "        np.save(f,x)\n",
    "    print('saved as '+'switchRnnXData_id:'+str(currentId)+'.npy')     \n",
    "    with open('data/switch/switchRnnYData_id:'+str(currentId)+'.npy', 'wb') as f:\n",
    "        np.save(f,y)\n",
    "    print('saved as '+'switchRnnYData_id:'+str(currentId)+'.npy') \n",
    "    print('=========================================')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape => (5, 10, 292)\n",
      "Y.shape => (5, 10, 1)\n",
      "saved as switchRnnXData_id:10.130.2.1.npy\n",
      "saved as switchRnnYData_id:10.130.2.1.npy\n",
      "=========================================\n",
      "X.shape => (5, 10, 292)\n",
      "Y.shape => (5, 10, 1)\n",
      "saved as switchRnnXData_id:10.129.2.1.npy\n",
      "saved as switchRnnYData_id:10.129.2.1.npy\n",
      "=========================================\n",
      "X.shape => (5, 10, 292)\n",
      "Y.shape => (5, 10, 1)\n",
      "saved as switchRnnXData_id:10.128.2.1.npy\n",
      "saved as switchRnnYData_id:10.128.2.1.npy\n",
      "=========================================\n",
      "X.shape => (5, 10, 292)\n",
      "Y.shape => (5, 10, 1)\n",
      "saved as switchRnnXData_id:10.131.0.1.npy\n",
      "saved as switchRnnYData_id:10.131.0.1.npy\n",
      "=========================================\n",
      "X.shape => (5, 10, 292)\n",
      "Y.shape => (5, 10, 1)\n",
      "saved as switchRnnXData_id:10.131.2.1.npy\n",
      "saved as switchRnnYData_id:10.131.2.1.npy\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "Persons = data['id'].unique() # array of all unique ids in other hand array of all diffrent persons\n",
    "lenPersons = len(data['id'].unique()) # number of all unique ids in other hand number of all diffrent persons\n",
    "for i in range(lenPersons):\n",
    "    fakeReccomendedSequance(numOfDays = 5,jobsPerADay = 8,currentId =Persons[i] , maxOfWorks = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switchRnnXDataX:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "--------------------------------\n",
      "switchRnnYDataY:\n",
      "[[[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]\n",
      "\n",
      " [[1.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [0.]]]\n"
     ]
    }
   ],
   "source": [
    "currentId = '10.128.2.1'\n",
    "with open('data/switch/switchRnnXData_id:'+str(currentId)+'.npy', 'rb') as f:\n",
    "        switchRnnXDataX = np.load(f)\n",
    "with open('data/switch/switchRnnYData_id:'+str(currentId)+'.npy', 'rb') as f:\n",
    "        switchRnnYDataY = np.load(f)\n",
    "print('switchRnnXDataX:')               \n",
    "print(switchRnnXDataX)\n",
    "print('--------------------------------')\n",
    "print('switchRnnYDataY:')  \n",
    "print(switchRnnYDataY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A partial insight into our Architecture\n",
    "\n",
    "![Alt text](images/generative%20_lstm.png)\n",
    "\n",
    "That is our TRM diagram that can use for no_time base and time base TRM\n",
    "\n",
    "In our STRM first we should train both no_time base and time base models with particular data thet you have seen before in last part . after that we can use our no_time base TRM in test phase wich recommending a series of tasks immediately after completing the previous tasks in this part we can chek our job with asking a question or look even more closely to see if the user did them (accepted) or rejected them ! if they accepted our recommendation it means that we can do like this:\n",
    "\n",
    "![Alt text](images/trm_data.png)\n",
    "\n",
    "in this part we can check after one day(daily)(because our model and data designed daily) and make this kinds of data.\n",
    "a sequence of recommende works and ther acceptation lable for our recommended works ! after that we can train another model called Switch to learn after our first learning on no_time base model. after learning on Switch \n",
    "we can feed our prediction on no_time base model to this Switch model to know if we should recomend this work now or we have to wait until its time !(or if we have to use no_time base or time base model for this particular work sequence)\n",
    "\n",
    "![Alt text](images/trm_model.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally Keras Model !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 09:47:10.825764: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import log\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for single id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RnnWorkDataOH.shape => (55, 95, 293)\n"
     ]
    }
   ],
   "source": [
    "PersonId = '10.130.2.1'\n",
    "with open('data/no_time_base/RnnWorkDataOH_id:'+str(PersonId)+'.npy', 'rb') as f:\n",
    "    RnnWorkDataOH = np.load(f)\n",
    "print('RnnWorkDataOH.shape =>',RnnWorkDataOH.shape)  #(m,Tx,n_values)\n",
    "#model parameters :\n",
    "n_values = RnnWorkDataOH.shape[-1] # number of work values => 293\n",
    "Tx = RnnWorkDataOH.shape[1] # Sequence lenght  => 95 + 1\n",
    "m = RnnWorkDataOH.shape[0] # number of training examples  => 55\n",
    "n_a = 32  # number of dimensions for the hidden state of each LSTM cell. hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 95, 293)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RnnWorkDataOH.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About dataset...\n",
    "\n",
    "- `X`: This is an (m, $T_x$, 293) dimensional array. \n",
    "    - You have m training examples, each of which is a snippet of $T_x = 95 $ works per a day. \n",
    "    - At each time step, the input is one of 293 different possible values, represented as a one-hot vector. \n",
    "        - For example, X[i,t,:] is a one-hot vector representing the value of the i-th example at time t. \n",
    "\n",
    "- `Y`: a $(T_y, m, 293)$ dimensional array\n",
    "    - This is essentially the same as `X`, but shifted one step to the left (to the past). \n",
    "    - Notice that the data in `Y` is **reordered** to be dimension $(T_y, m, 293)$, where $T_y = T_x$. This format makes it more convenient to feed into the LSTM later.\n",
    "    - Similar to the dinosaur assignment, you're using the previous values to predict the next value.\n",
    "        - So your sequence model will try to predict $y^{\\langle t \\rangle}$ given $x^{\\langle 1\\rangle}, \\ldots, x^{\\langle t \\rangle}$. \n",
    "\n",
    "- `n_values`: The number of unique values in this dataset. This should be 293. \n",
    "\n",
    "- for converting our corpus to X and Y we can add zeros vector fisrt of our data to build X\n",
    "and add zeros vector to the end to have Y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XY(dataset):\n",
    "    # dataset named RnnWorkDataOH \n",
    "    #this vectorized function stacks a zero vec before X and after Y ...\n",
    "    dim1,dim2,dim3 = dataset.shape\n",
    "    #-----------------------------------\n",
    "    X = np.zeros((dim1, dim2 + 1, dim3))\n",
    "    Y = np.zeros((dim1, dim2 + 1, dim3))\n",
    "    #-----------------------------------\n",
    "    X[:,1:,:] = dataset\n",
    "    Y[:,:-1,:] = dataset\n",
    "    #-----------------------------------\n",
    "    Y = np.swapaxes(Y,0,1) #but why you should use this? run next cell...\n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4 0 5 4]\n",
      "  [4 3 2 6]\n",
      "  [2 2 6 5]]\n",
      "\n",
      " [[1 5 1 7]\n",
      "  [8 4 8 0]\n",
      "  [5 0 4 0]]]\n",
      "--------------\n",
      "[[[4 0 5 4]\n",
      "  [1 5 1 7]]\n",
      "\n",
      " [[4 3 2 6]\n",
      "  [8 4 8 0]]\n",
      "\n",
      " [[2 2 6 5]\n",
      "  [5 0 4 0]]]\n"
     ]
    }
   ],
   "source": [
    "### swapaxes example\n",
    "np.random.seed(seed=2)\n",
    "arr_test = (np.random.rand(2,3,4) *10).astype(int) #(m,tx,n)\n",
    "print(arr_test)\n",
    "print('--------------')\n",
    "print(np.swapaxes(arr_test,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = XY(RnnWorkDataOH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence generation uses a for-loop\n",
    "* If you're building an RNN where, at test time, the entire input sequence $x^{\\langle 1 \\rangle}, x^{\\langle 2 \\rangle}, \\ldots, x^{\\langle T_x \\rangle}$ is given in advance, then Keras has simple built-in functions to build the model. \n",
    "* However, for **sequence generation, at test time you won't know all the values of $x^{\\langle t\\rangle}$ in advance**.\n",
    "* Instead, you'll generate them one at a time using $x^{\\langle t\\rangle} = y^{\\langle t-1 \\rangle}$. \n",
    "    * The input at time \"t\" is the prediction at the previous time step \"t-1\".\n",
    "* So you'll need to implement your own for-loop to iterate over the time steps. \n",
    "#### Shareable weights\n",
    "* The function `trmModel()` will call the LSTM layer $T_x$ times using a for-loop.\n",
    "* It is important that all $T_x$ copies have the same weights. \n",
    "    - The $T_x$ steps should have shared weights that aren't re-initialized.\n",
    "* Referencing a globally defined shared layer will utilize the same layer-object instance at each time step.\n",
    "* The key steps for implementing layers with shareable weights in Keras are: \n",
    "1. Define the layer objects (you'll use global variables for this).\n",
    "2. Call these objects when propagating the input.\n",
    "\n",
    "#### 3 types of layers\n",
    "* The layer objects you need for global variables have been defined.  \n",
    "    * Just run the next cell to create them! \n",
    "* Please read the Keras documentation and understand these layers: \n",
    "    - [Reshape()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape): Reshapes an output to a certain shape.\n",
    "    - [LSTM()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Long Short-Term Memory layer\n",
    "    - [Dense()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): A regular fully-connected neural network layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-08 09:47:17.616625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "reshaper = Reshape((1, n_values),name='myReshaper')                # Used in Step 2.B of trmModel(), below\n",
    "LSTM_cell = LSTM(n_a, return_state = True,name='myLSTM_cell')      # Used in Step 2.C\n",
    "densor = Dense(n_values, activation='softmax',name='myDensor')     # Used in Step 2.D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `reshaper`, `LSTM_cell` and `densor` are globally defined layer objects that you'll use to implement `trmModel()`. \n",
    "* In order to propagate a Keras tensor object X through one of these layers, use `layer_object()`.\n",
    "    - For one input, use `layer_object(X)`\n",
    "    - For more than one input, put the inputs in a list: `layer_object([X1,X2])`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "### trmModel\n",
    "\n",
    "Implement `trmModel()`.\n",
    "\n",
    "#### Inputs (given)\n",
    "\n",
    "* The `Input()` layer is used for defining the input `X` as well as the initial hidden state 'a0' and cell state `c0`.\n",
    "* The `shape` parameter takes a tuple that does not include the batch dimension (`m`).\n",
    "    - For example,\n",
    "    ```Python\n",
    "    X = Input(shape=(Tx, n_values)) # X has 3 dimensions and not 2: (m, Tx, n_values)\n",
    "    ```\n",
    "    \n",
    "#### Step 1: Outputs\n",
    "\n",
    "* Create an empty list \"outputs\" to save the outputs of the LSTM Cell at every time step.\n",
    "\n",
    "#### Step 2: Loop through time steps\n",
    "* Loop for $t \\in 1, \\ldots, T_x$:\n",
    "\n",
    "#### 2A. Select the 't' time-step vector from `X`.\n",
    "* X has the shape (m, Tx, n_values).\n",
    "* The shape of the 't' selection should be (n_values,). \n",
    "* Recall that if you were implementing in numpy instead of Keras, you would extract a slice from a 3D numpy array like this:\n",
    "```Python\n",
    "var1 = array1[:,1,:]\n",
    "```\n",
    "    \n",
    "#### 2B. Reshape `x` to be (1, n_values).\n",
    "* Use the `reshaper()` layer.  This is a function that takes the previous layer as its input argument.\n",
    "\n",
    "#### 2C. Run `x` through one step of `LSTM_cell`.\n",
    "\n",
    "* Initialize the `LSTM_cell` with the previous step's hidden state $a$ and cell state $c$. \n",
    "* Use the following formatting:\n",
    "```python\n",
    "next_hidden_state, _, next_cell_state = LSTM_cell(inputs=input_x, initial_state=[previous_hidden_state, previous_cell_state])\n",
    "```\n",
    "    * Choose appropriate variables for inputs, hidden state and cell state.\n",
    "\n",
    "#### 2D. Dense layer\n",
    "* Propagate the LSTM's hidden state through a dense+softmax layer using `densor`. \n",
    "    \n",
    "#### 2E. Append output\n",
    "* Append the output to the list of \"outputs\".\n",
    "\n",
    "#### Step 3: After the loop, create the model\n",
    "* Use the Keras `Model` object to create a model. There are two ways to instantiate the `Model` object. One is by subclassing, which you won't use here. Instead, you'll use the highly flexible Functional API, which you may remember from an earlier assignment in this course! With the Functional API, you'll start from your Input, then specify the model's forward pass with chained layer calls, and finally create the model from inputs and outputs.\n",
    "\n",
    "* Specify the inputs and output like so:\n",
    "```Python\n",
    "model = Model(inputs=[input_x, initial_hidden_state, initial_cell_state], outputs=the_outputs)\n",
    "```\n",
    "    * Then, choose the appropriate variables for the input tensor, hidden state, cell state, and output.\n",
    "* See the documentation for [Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is reshapor in example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape => (None, 90, 293)\n",
      "x[:,1,:].shape => (None, 293)\n",
      "Reshape()(x).shape => (None, 1, 293)\n"
     ]
    }
   ],
   "source": [
    "x_test = Input(shape=(90, 293)) \n",
    "print('x.shape =>',x_test.shape)\n",
    "x_test = x_test[:,1,:]\n",
    "print('x[:,1,:].shape =>',x_test.shape)\n",
    "x_test = Reshape((1,293))(x_test)\n",
    "print('Reshape()(x).shape =>',x_test.shape) # so we have extra dim in axis 1 (expand dim!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTrmModel(Tx, LSTM_cell, densor, reshaper):\n",
    "    n_a = LSTM_cell.units\n",
    "    n_values = densor.units\n",
    "    #---------------------------------\n",
    "    X = Input(shape = (Tx,n_values))\n",
    "    X = Input(shape=(Tx, n_values))\n",
    "    a0 = Input(shape = (n_a,),name = 'a0')\n",
    "    c0 = Input(shape = (n_a,),name = 'c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    outputs = []\n",
    "    for i in range(Tx):\n",
    "        x = X[:,i,:]\n",
    "        x = reshaper(x)\n",
    "        a, _, c= LSTM_cell(inputs= x , initial_state=[a,c])\n",
    "        out = densor(a)\n",
    "        outputs.append(out)\n",
    "    #---------------------------------\n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)   \n",
    "    #---------------------------------\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trmModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trmModel(Tx, LSTM_cell, densor, reshaper):\n",
    "    \"\"\"\n",
    "    Implement the trmModel composed of Tx LSTM cells where each cell is responsible\n",
    "    for learning the following note based on the previous note and context.\n",
    "    Each cell has the following schema: \n",
    "            [X_{t}, a_{t-1}, c0_{t-1}] -> RESHAPE() -> LSTM() -> DENSE()\n",
    "    Arguments:\n",
    "        Tx -- length of the sequences in the corpus\n",
    "        LSTM_cell -- LSTM layer instance\n",
    "        densor -- Dense layer instance\n",
    "        reshaper -- Reshape layer instance\n",
    "    \n",
    "    Returns:\n",
    "        model -- a keras instance model with inputs [X, a0, c0]\n",
    "    \"\"\"\n",
    "    # Get the shape of input values\n",
    "    n_values = densor.units\n",
    "    #------------------------------------------------\n",
    "    # Get the number of the hidden state vector\n",
    "    n_a = LSTM_cell.units\n",
    "    #------------------------------------------------\n",
    "    # Define the input layer and specify the shape\n",
    "    X = Input(shape=(Tx, n_values),name='X') #(None, Tx, n_values)\n",
    "    #------------------------------------------------\n",
    "    # Define the initial hidden state a0 and initial cell state c0\n",
    "    # using `Input`\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    #-------------------------------------------------\n",
    "    #Create empty list to append the outputs while you iterate (â‰ˆ1 line)\n",
    "    outputs = []\n",
    "    #-------------------------------------------------\n",
    "    #Loop over tx\n",
    "    for t in range(Tx):\n",
    "        #--------------------------------------------- \n",
    "        #Select the \"t\"th time step vector from X. \n",
    "        x = X[:,t,:] #(None, n_values)\n",
    "        #Use reshaper to reshape x to be (1, n_values) (â‰ˆ1 line)\n",
    "        x = reshaper(x) #(None, 1, n_values)\n",
    "        #Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a,c])\n",
    "        #Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "        #Add the output to \"outputs\"\n",
    "        outputs.append(out)\n",
    "    #-------------------------------------------------   \n",
    "    #Create model instance\n",
    "    model = Model(inputs=[X, a0, c0], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole_seq_output => (32, 10, 4)\n",
      "final_memory_state => (32, 4)\n",
      "final_carry_state => (32, 4)\n",
      "--------------------------------\n",
      "whole_seq_output => (32, 10, 4)\n",
      "--------------------------------\n",
      "lstm1 => (32, 4)\n",
      "state_h => (32, 4)\n",
      "state_c => (32, 4)\n",
      "--------------------------------\n",
      "output => (32, 4)\n"
     ]
    }
   ],
   "source": [
    "#please run this Keras example to get more ituation\n",
    "inputs = random.normal([32, 10, 8])\n",
    "lstm = LSTM(4)\n",
    "#---------------------------------------------------------------------\n",
    "lstm = LSTM(4, return_sequences=True, return_state=True)\n",
    "whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n",
    "print('whole_seq_output =>',whole_seq_output.shape)\n",
    "print('final_memory_state =>',final_memory_state.shape)\n",
    "print('final_carry_state =>',final_carry_state.shape)\n",
    "print('--------------------------------')\n",
    "#---------------------------------------------------------------------\n",
    "lstm = LSTM(4, return_sequences=True, return_state=False)\n",
    "whole_seq_output = lstm(inputs)\n",
    "print('whole_seq_output =>',whole_seq_output.shape)\n",
    "print('--------------------------------')\n",
    "#---------------------------------------------------------------------\n",
    "lstm = LSTM(4, return_sequences=False, return_state=True)\n",
    "lstm1, state_h, state_c,= lstm(inputs)\n",
    "print('lstm1 =>',lstm1.shape)\n",
    "print('state_h =>',state_h.shape)\n",
    "print('state_c =>',state_c.shape)\n",
    "print('--------------------------------') # Note that lstm1 and state_h are same\n",
    "#---------------------------------------------------------------------\n",
    "lstm = LSTM(4, return_sequences=False, return_state=False)\n",
    "output = lstm(inputs)\n",
    "print('output =>',output.shape)\n",
    "#---------------------------------------------------------------------\n",
    "inputs = np.zeros(shape=(32, 10, 8))\n",
    "lstm = LSTM(4)\n",
    "output = lstm(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the model object\n",
    "* Run the following cell to define your model. \n",
    "* We will use `Tx=95 + 1`. \n",
    "* This cell may take a few seconds to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trmModel(Tx=96, LSTM_cell=LSTM_cell, densor=densor, reshaper=reshaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293), (None, 293)]\n"
     ]
    }
   ],
   "source": [
    "print((model.output_shape)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model for training\n",
    "* You now need to compile your model to be trained. \n",
    "* We will use:\n",
    "    - optimizer: Adam optimizer\n",
    "    - Loss function: categorical cross-entropy (for multi-class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = LSTM_cell.units\n",
    "m = 55\n",
    "a0 = np.zeros((m, n_a))\n",
    "c0 = np.zeros((m, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([np.array(X), a0, c0], list(Y), epochs=10, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 1: 533.5243530273438\n",
      "loss at epoch 10 : 185.4423065185547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb9082e0850>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"loss at epoch 1: {history.history['loss'][0]}\")\n",
    "print(f\"loss at epoch \" + str(len(history.epoch))+f\" : {history.history['loss'][len(history.epoch) - 1]}\")\n",
    "#fig = plt.figure(figsize=(25, 10))\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice ;) !!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Generating Sequence(single input without beam search)\n",
    "\n",
    "You now have a trained model which has learned the patterns of a user tasks. You can now use this model to synthesize new Sequence! \n",
    "\n",
    "<a name='3-1'></a>\n",
    "### 3.1 - Predicting & Sampling\n",
    "\n",
    "<img src=\"images/music_gen.png\" style=\"width:600;height:400px;\">\n",
    "<center><caption><b><font color='purple'>Figure 2: Generating new values in an LSTM </b></font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At each step of sampling, you will:\n",
    "* Take as input the activation '`a`' and cell state '`c`' from the previous state of the LSTM.\n",
    "* Forward propagate by one step.\n",
    "* Get a new output activation, as well as cell state. \n",
    "* The new activation '`a`' can then be used to generate the output using the fully connected layer, `densor`. \n",
    "\n",
    "#### Initialization\n",
    "* You'll initialize the following to be zeros:\n",
    "    * `x0` \n",
    "    * hidden state `a0` \n",
    "    * cell state `c0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why should we use \n",
    " - tf.math.argmax()\n",
    " - tf.one_hot()\n",
    " - RepeatVector() ??\n",
    "\n",
    "temp = tf.math.argmax([[4,40,4],[4,40,4]],-1)\n",
    "print(temp)\n",
    "temp = tf.one_hot(temp,5)\n",
    "print(temp)\n",
    "RepeatVector(1)(temp)\n",
    "\n",
    "tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
    "tf.Tensor(\n",
    "[[0. 1. 0. 0. 0.]\n",
    " [0. 1. 0. 0. 0.]], shape=(2, 5), dtype=float32)\n",
    "<tf.Tensor: shape=(2, 1, 5), dtype=float32, numpy=\n",
    "array([[[0., 1., 0., 0., 0.]],\n",
    "\n",
    "       [[0., 1., 0., 0., 0.]]], dtype=float32)>'''\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uniInputSequenceInferenceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniInputSequenceInferenceModel(LSTM_cell, densor,Ty = 10):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    \n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the shape of input values\n",
    "    n_values = densor.units\n",
    "    # Get the number of the hidden state vector\n",
    "    n_a = LSTM_cell.units\n",
    "    \n",
    "    # Define the input of your model with a shape \n",
    "    x0 = Input(shape=(1, n_values))\n",
    "    \n",
    "    \n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0')\n",
    "    c0 = Input(shape=(n_a,), name='c0')\n",
    "    a = a0\n",
    "    c = c0\n",
    "    x = x0\n",
    "\n",
    "    # Step 1: Create an empty list of \"outputs\" to later store your predicted values (â‰ˆ1 line)\n",
    "    outputs = []\n",
    "    \n",
    "    # Step 2: Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        # Step 2.A: Perform one step of LSTM_cell. Use \"x\", not \"x0\" (â‰ˆ1 line)\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a,c])\n",
    "        \n",
    "        # Step 2.B: Apply Dense layer to the hidden state output of the LSTM_cell (â‰ˆ1 line)\n",
    "        out = densor(a)\n",
    "        # Step 2.C: Append the prediction \"out\" to \"outputs\". out.shape = (None, 90) (â‰ˆ1 line)\n",
    "        outputs.append(out)\n",
    " \n",
    "        # Step 2.D: \n",
    "        # Select the next value according to \"out\",\n",
    "        # Set \"x\" to be the one-hot representation of the selected value\n",
    "        # See instructions above.\n",
    "        x = tf.math.argmax(out,-1)\n",
    "        x = tf.one_hot(x,n_values)\n",
    "        # Step 2.E: \n",
    "        # Use RepeatVector(1) to convert x into a tensor with shape=(None, 1, 90)\n",
    "        x = RepeatVector(1)(x)\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (â‰ˆ1 line)\n",
    "    inference_model = Model(inputs = [x0,a0,c0] , outputs = outputs)\n",
    "    \n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What is sequenceInferenceModel(LSTM_cell, densor) type? \n",
    "<keras.engine.functional.Functional at 0x7fcee9e5f370>'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_inference_model = uniInputSequenceInferenceModel(LSTM_cell, densor, Ty = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 1, 293), (None, 32), (None, 32)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_inference_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 293), (None, 293), (None, 293)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_inference_model.output_shape[0:3] # insted of 3 in fact it is 96 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_initializer = np.zeros((1, 1, n_values))\n",
    "a_initializer = np.zeros((1, n_a))\n",
    "c_initializer = np.zeros((1, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 15s 15s/step\n"
     ]
    }
   ],
   "source": [
    "uniModelPred  = uni_inference_model.predict([x_initializer, a_initializer, c_initializer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = X[1,0:10,:]\n",
    "testX = np.expand_dims(testX,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiInputSequenceInferenceModel(LSTM_cell, densor,Ty,Tx):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "    \n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    sequence -- sequence of works you have done so far in that day\n",
    "\n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    # Get the shape of input values\n",
    "    n_values = densor.units\n",
    "    # Get the number of the hidden state vector\n",
    "    n_a = LSTM_cell.units\n",
    "\n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, n_values),name='X') #(None, Tx, n_values)\n",
    "\n",
    "    # Tx of current sequence in other hand number of works you have done so far in that day\n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0') #init\n",
    "    c0 = Input(shape=(n_a,), name='c0') #init\n",
    "    a = a0 \n",
    "    c = c0 \n",
    "    \n",
    "    #no need to save generated outputs we just need last a ,c and x\n",
    "    for t in range(Tx):\n",
    "        #Select the \"t\"th time step vector from X. \n",
    "        x = X[:,t,:] #(None, n_values)\n",
    "        #Use reshaper to reshape x to be (1, n_values)\n",
    "        x = reshaper(x) #(None, 1, n_values)\n",
    "        #Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a,c])\n",
    "        #Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "\n",
    "    # So now we have new a, c\n",
    "    x = tf.math.argmax(out,-1)\n",
    "    x = tf.one_hot(x,n_values)\n",
    "    # Use RepeatVector(1) to convert x into a tensor with shape=(None, 1, 90)\n",
    "    x = RepeatVector(1)(x)\n",
    "\n",
    "    #Create an empty list of \"outputs\" to later store your predicted values \n",
    "    outputs = []\n",
    "    #Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        #Perform one step of LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a,c])\n",
    "        #Apply Dense layer to the hidden state output of the LSTM_cell\n",
    "        out = densor(a)\n",
    "        #Append the prediction \"out\" to \"outputs\". out.shape = (None, 90)\n",
    "        outputs.append(out)\n",
    "        # Select the next value according to \"out\",\n",
    "        # Set \"x\" to be the one-hot representation of the selected value\n",
    "        x = tf.math.argmax(out,-1)\n",
    "        x = tf.one_hot(x,n_values)\n",
    "        # Use RepeatVector(1) to convert x into a tensor with shape=(None, 1, 90)\n",
    "        x = RepeatVector(1)(x)\n",
    "        \n",
    "    # Step 3: Create model instance with the correct \"inputs\" and \"outputs\" (â‰ˆ1 line)\n",
    "    inference_model = Model(inputs = [X,a0,c0] , outputs = outputs)\n",
    "    \n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this model to develop other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 sec run time!!! so heavy because U most for over this!! for solution go next cells ...\n",
    "multi_inference_model = multiInputSequenceInferenceModel(LSTM_cell, densor, Ty = 50,Tx = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on multi input inference model (batchSize = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 18s 18s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 1, 293)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiModelPred = multi_inference_model.predict([testX, a_initializer, c_initializer])\n",
    "np.array(multiModelPred).shape #(Ty, m, n_values) (50, 1, 293)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on multi input inference model (batchSize > 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing x,a,c for model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX2 = np.stack((np.squeeze(testX),np.squeeze(testX))) #(m,Tx,n_values) (2, 10, 293)\n",
    "testA2 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "testC2 = np.zeros((2,32))  #(m,n_values) (2, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 2, 293)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiModelPredBatch = multi_inference_model.predict([testX2, testA2, testC2])\n",
    "np.array(multiModelPredBatch).shape #(Ty, m, n_values) (50, 2, 293)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accessing prediction of training example = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 293)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(multiModelPredBatch)[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''multi_inference_model\n",
    "<keras.engine.functional.Functional at 0x7f8133e46c40>'''\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing multiModelPred uniModelPred (predictions...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.772 0.014 0.053 ... 0.    0.    0.   ]]\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(multiModelPred).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.006 0.005 0.006 ... 0.003 0.003 0.003]]\n",
      "\n",
      " [[0.016 0.009 0.011 ... 0.003 0.003 0.003]]\n",
      "\n",
      " [[0.082 0.02  0.031 ... 0.002 0.002 0.003]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]\n",
      "\n",
      " [[0.772 0.014 0.053 ... 0.    0.    0.   ]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(uniModelPred).round(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in this part we made a specific model for each number of inputs ... to make Beam Search Faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this part we made a specific model for each number of inputs ... to make Beam Search Faster\n",
    "models = [0]\n",
    "for nOfInputs in range(1, 10):\n",
    "    globals()[f\"inferenceModel_{nOfInputs}Inputs\"] = multiInputSequenceInferenceModel(LSTM_cell, densor, Ty = 1,Tx = nOfInputs)\n",
    "    models.append(globals()[f\"inferenceModel_{nOfInputs}Inputs\"])\n",
    "\n",
    "# 15 sec for building 9 models?? greate !! ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 1, 293), (None, 32), (None, 32)]\n",
      "(None, 293)\n",
      "----------------------------------------\n",
      "[(None, 2, 293), (None, 32), (None, 32)]\n",
      "(None, 293)\n",
      "----------------------------------------\n",
      "[(None, 3, 293), (None, 32), (None, 32)]\n",
      "(None, 293)\n"
     ]
    }
   ],
   "source": [
    "#accessing to models\n",
    "print(models[1].input_shape) # access by index from models array (ex index 2 includes model with 2 input)\n",
    "print(inferenceModel_1Inputs.output_shape)# access by name ...\n",
    "print('----------------------------------------')\n",
    "print(models[2].input_shape) # access by index from models array (ex index 2 includes model with 2 input)\n",
    "print(inferenceModel_2Inputs.output_shape)# access by name ...\n",
    "print('----------------------------------------')\n",
    "print(models[3].input_shape) # access by index from models array (ex index 3 includes model with 3 input)\n",
    "print(inferenceModel_3Inputs.output_shape)# access by name ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on multi input (1 input , 2 inputs ,... ) inference model (batchSize = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape => [(None, 1, 293), (None, 32), (None, 32)]\n",
      "output_shape => (None, 293)\n",
      "1/1 [==============================] - 1s 879ms/step\n",
      "input1ModelPred.shape => (2, 293)\n"
     ]
    }
   ],
   "source": [
    "# 1 input model test\n",
    "#init Data \n",
    "testX1 = np.stack((testX[:,1,:],testX[:,1,:])) #(m,Tx,n_values) (2, 1, 293)\n",
    "testA1 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "testC1 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "#model\n",
    "input1Model = models[1]\n",
    "print('input_shape =>',input1Model.input_shape)\n",
    "print('output_shape =>',input1Model.output_shape)\n",
    "input1ModelPred = input1Model.predict([testX1,testA1,testC1])\n",
    "#print('input1ModelPred =>',np.array(input1ModelPred))\n",
    "print('input1ModelPred.shape =>',np.array(input1ModelPred).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape => [(None, 2, 293), (None, 32), (None, 32)]\n",
      "output_shape => (None, 293)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "input2ModelPred.shape => (2, 293)\n"
     ]
    }
   ],
   "source": [
    "# 2 input model test\n",
    "#init Data \n",
    "temp = np.squeeze(np.stack((testX[:,1,:],testX[:,1,:])))\n",
    "testX2 = np.stack((temp,temp),axis = 1) #(m,Tx,n_values) (2, 2, 293)\n",
    "testA2 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "testC2 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "#model\n",
    "input2Model = models[2]\n",
    "print('input_shape =>',input2Model.input_shape)\n",
    "print('output_shape =>',input2Model.output_shape)\n",
    "input2ModelPred = input2Model.predict([testX2,testA2,testC2])\n",
    "#print('input2ModelPred =>',np.array(input2ModelPred))\n",
    "print('input2ModelPred.shape =>',np.array(input2ModelPred).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape => [(None, 3, 293), (None, 32), (None, 32)]\n",
      "output_shape => (None, 293)\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb90ab12af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "input3ModelPred.shape => (2, 293)\n"
     ]
    }
   ],
   "source": [
    "# 3 input model test\n",
    "#init Data \n",
    "temp = np.squeeze(np.stack((testX[:,1,:],testX[:,1,:])))\n",
    "testX3 = np.stack((temp,temp,temp),axis = 1) #(m,Tx,n_values) (2, 3, 293)\n",
    "testA3 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "testC3 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "#model\n",
    "input3Model = models[3]\n",
    "print('input_shape =>',input3Model.input_shape)\n",
    "print('output_shape =>',input3Model.output_shape)\n",
    "input3ModelPred = input3Model.predict([testX3,testA3,testC3])\n",
    "#print('input3ModelPred =>',np.array(input3ModelPred))\n",
    "print('input3ModelPred.shape =>',np.array(input3ModelPred).shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search\n",
    "\n",
    "first what is beam search . imagin you aleady have a trained model on TRM that recommends tasks in a sequence!! thats awesome! but you have two options 1- model can return(recommend) one single next work that is selected py highest probability! but if you choose highest probability in each step, it doesn't garantias us to give highest multiplied probability!! Perhaps you stsrted with low probability task but in sequence you get highest!! so we use probabilistic algorythm called Beam Search!\n",
    "\n",
    "\n",
    "#### The beam width tips\n",
    "The beam width B is a parameter for beam search. Large values of B yield to better result but with slower performance and increased memory. Small values of B lead to worse results but is less computationally intensive. A standard value for B is around 10\n",
    "\n",
    "##### important note : So in general AI team recoomended you to use Sequence Reccomendation with Beam Search\n",
    "or fisrt calculate Beam Search then just use first recommended task from that sequence\n",
    "\n",
    "\n",
    "![Alt text](images/beam_andrew%20Ng.png)\n",
    "\n",
    "## Beam Search Implimentation\n",
    "\n",
    "![Alt text](images/beam_diagram.jpg)\n",
    "\n",
    "## Beam Search Formula\n",
    "\n",
    "![Alt text](images/beam_formula.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexToModelInput(indexs,n_values = 293):\n",
    "    oh = tf.one_hot(indexs,n_values,axis = -1)\n",
    "    sw = np.swapaxes(oh,0,1)\n",
    "    return sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(tx,m) to (m,Tx,n_values)\n",
    "arr = np.array([[1,2,3],[5,6,0],[5,6,0]])\n",
    "indexToModelInput(arr,n_values = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def currentValue(matrix ,width = 3):\n",
    "    fattenMatrix = matrix.flatten()\n",
    "    value = fattenMatrix[np.sort((-matrix).flatten().argsort()[0:width])]\n",
    "    return (np.expand_dims(value,axis=0)).T\n",
    "#----------------------------------------------------------------\n",
    "def LastIndexs(matrix,indexs,width = 3 ,n_values = n_values):\n",
    "    sort = (-matrix).flatten().argsort()[0:width]\n",
    "    try :\n",
    "        newIndexs = indexs[: , np.sort(sort) // n_values] \n",
    "        newIndex = np.sort(sort) % n_values\n",
    "        newIndex = np.expand_dims(newIndex,axis=0)\n",
    "        newIndexs = np.concatenate((newIndexs, newIndex))\n",
    "        return newIndexs\n",
    "    except :\n",
    "        return np.expand_dims((np.sort(sort) % n_values),axis=0)\n",
    "#----------------------------------------------------------------\n",
    "def epsilonFunc(epsilonType):\n",
    "    if epsilonType == '32':\n",
    "        epsilon = np.finfo(np.float32).eps\n",
    "    if epsilonType == '64':\n",
    "        epsilon = np.finfo(np.float64).eps\n",
    "    if epsilonType == 'no_epsilon':\n",
    "        epsilon = 0 \n",
    "    return epsilon    \n",
    "#----------------------------------------------------------------\n",
    "def beamSearch(lastSoftmax, lastA, lastC, models, Ty_max, epsilonType = '64', show = True ,auto = True):\n",
    "    #epsilon for preventing from underflow\n",
    "    epsilon = epsilonFunc(epsilonType)\n",
    "    # initializing indexs\n",
    "    indexs = 0\n",
    "    values = []\n",
    "    #----------------------------------------------------------------\n",
    "    for i in range(Ty_max):\n",
    "        # --- hyper prameter t ---\n",
    "        t = (i + 1) ** 0.7\n",
    "        # ------------------------\n",
    "        if i == 0 : \n",
    "            modelMatrix = lastSoftmax\n",
    "            indexs = LastIndexs(modelMatrix,indexs,width = 3 ,n_values = n_values)\n",
    "            zeroIndex = indexs.copy() #just for printer\n",
    "        #------------------------------------------------------------    \n",
    "        value = currentValue(modelMatrix ,width = 3)\n",
    "        valueCopy = value.copy()\n",
    "        #------------------------------------------------------------\n",
    "        #select models[i+ 1] with i + 1 input ... to acive modelMatrix\n",
    "        modelMatrix = models[i+1].predict([indexToModelInput(indexs,n_values),lastA,lastC]) \n",
    "        modelMatrixCopy = modelMatrix.copy() #just for printer\n",
    "        if i == 0:\n",
    "            value = log(value + epsilon) # preventing -inf\n",
    "        modelMatrix = value + log(modelMatrix + epsilon) #epsilon for preventing -inf and log for preventing memory underflow\n",
    "        values.append((value/t).tolist())\n",
    "        #------------------------------------------------------------\n",
    "        indexs = LastIndexs(modelMatrix,indexs,width = 3 ,n_values = n_values)\n",
    "        #---------------------------Printer--------------------------\n",
    "        if show :\n",
    "            print('------------- step '+str(i)+' -------------')\n",
    "            if i == 0:\n",
    "                print('firstSoftmax.shape => \\n',lastSoftmax.shape)\n",
    "                print('firstSoftmax => \\n',lastSoftmax)\n",
    "                print('zeroIndex => \\n',zeroIndex)\n",
    "            print('number of model inputs =>' , i+1)   \n",
    "            print('valueCopy => \\n',valueCopy)\n",
    "            print('modelMatrix => \\n',modelMatrix) \n",
    "            print('modelMatrix.shape => \\n',modelMatrix.shape)\n",
    "            #print('value => \\n',value)\n",
    "            print('indexs => \\n',indexs)\n",
    "    #------------------------------------------------------------\n",
    "    value = currentValue(modelMatrix ,width = 3) \n",
    "    if show :\n",
    "        print('finalValue => \\n',value)  \n",
    "    #---------------------------------------------\n",
    "    values.append((value/t).tolist())\n",
    "    values = np.array(values)\n",
    "    #-------- normalized beam search -------------\n",
    "    swapedValues = np.swapaxes(values.copy(),0,2)\n",
    "    valuesLen = swapedValues.shape[-1]\n",
    "    beam_width = swapedValues.shape[1]\n",
    "    row = values.argmax() // valuesLen\n",
    "    col = values.argmax() %  valuesLen\n",
    "    swapedValues = np.squeeze(swapedValues,axis = 0)\n",
    "    autoBeamSequence = indexs.T[row,:col +1]\n",
    "    #---------------------------------------------\n",
    "    beamSequence = np.array(indexs)[:,value.argmax()]\n",
    "    #---------------------------------------------\n",
    "    if auto :\n",
    "        return autoBeamSequence\n",
    "    else :\n",
    "        return beamSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb91fdee700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xInit = np.expand_dims(testX[:,0,:],axis = 1) #(m,Tx,n_values) (1, 1, 293)\n",
    "aInit = np.zeros((1,32))                      #(1,n) (1, 32)\n",
    "cInit = np.zeros((1,32))                      #(1,n) (1, 32)\n",
    "#----------------------------------------------------------------\n",
    "#in this part we assume that we feed our X's to our model and thats time for generating\n",
    "# Function parameters\n",
    "show = True\n",
    "Ty_max = 6\n",
    "epsilonType = '64'\n",
    "indexs = 0\n",
    "lastSoftmax = models[1].predict([xInit,aInit,cInit])\n",
    "lastA = np.zeros((3,32))                      #(beam_width,n) (3, 32) processed hidden state from last model\n",
    "lastC = np.zeros((3,32))                      #(beam_width,n) (3, 32) processed hidden cell from last model\n",
    "models = models\n",
    "#----------------------------------------------------------------\n",
    "sequence = beamSearch(lastSoftmax, lastA, lastC, models, Ty_max,show=False,auto = False)\n",
    "sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple test for beam search ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1], [2], [3]]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = []\n",
    "arr1 = np.array([[1,2,3]]).T\n",
    "#arr1 = np.concatenate((arr1),axis=0)\n",
    "#arr1 = np.concatenate((arr1,arr1),axis=0)\n",
    "values.append(arr1.tolist())\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamSearchTest(mat ,lastSoftmax, lastA, lastC, models, Ty, epsilonType = '64', show = True):\n",
    "    #epsilon for preventing from underflow\n",
    "    epsilon = epsilonFunc(epsilonType)\n",
    "    # initializing indexs\n",
    "    indexs = 0\n",
    "    values = []\n",
    "    #----------------------------------------------------------------\n",
    "    for i in range(Ty):\n",
    "        t = (i + 1) ** 0.7\n",
    "        if i == 0 : \n",
    "            modelMatrix = lastSoftmax\n",
    "            indexs = LastIndexs(modelMatrix,indexs,width = 3 ,n_values = n_values)\n",
    "            zeroIndex = indexs.copy() #just for printer\n",
    "        #------------------------------------------------------------    \n",
    "        value = currentValue(modelMatrix ,width = 3)\n",
    "        valueCopy = value.copy()\n",
    "        values.append((value/t).tolist())\n",
    "        #------------------------------------------------------------\n",
    "        modelMatrix = mat[i]\n",
    "        #------------------------------------------------------------\n",
    "        modelMatrixCopy = modelMatrix.copy() #just for printer\n",
    "        if i == 0:\n",
    "            pass\n",
    "        modelMatrix = value + modelMatrix\n",
    "        #------------------------------------------------------------\n",
    "        indexs = LastIndexs(modelMatrix,indexs,width = 3 ,n_values = n_values)\n",
    "        #---------------------------Printer--------------------------\n",
    "        if show :\n",
    "            print('------------- step '+str(i)+' -------------')\n",
    "            if i == 0:\n",
    "                print('firstSoftmax.shape => \\n',lastSoftmax.shape)\n",
    "                print('firstSoftmax => \\n',lastSoftmax)\n",
    "                print('zeroIndex => \\n',zeroIndex)\n",
    "            print('number of model inputs =>' , i+1)   \n",
    "            print('valueCopy => \\n',valueCopy)\n",
    "            print('modelMatrix => \\n',modelMatrix) \n",
    "            print('modelMatrix.shape => \\n',modelMatrix.shape)\n",
    "            #print('value => \\n',value)\n",
    "            print('indexs => \\n',indexs)\n",
    "        #------------------------------------------------------------\n",
    "    value = currentValue(modelMatrix ,width = 3)\n",
    "    #---------------------------------------------\n",
    "    valueCopy = value.copy()\n",
    "    values.append((value/t).tolist())\n",
    "    values = np.array(values)\n",
    "    #-------- normalized beam search -------------\n",
    "    swapedValues = np.swapaxes(values.copy(),0,2)\n",
    "    valuesLen = swapedValues.shape[-1]\n",
    "    beam_width = swapedValues.shape[1]\n",
    "    row = values.argmax() // valuesLen\n",
    "    col = values.argmax() %  valuesLen\n",
    "    swapedValues = np.squeeze(swapedValues,axis = 0)\n",
    "    autoBeamSequence = (indexs.T)[row,:col +1]\n",
    "    #---------------------------------------------\n",
    "    if show : \n",
    "        print('values=> \\n' , values)\n",
    "        print('finalValue => \\n',value)     \n",
    "    return autoBeamSequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialized values for test ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- step 0 -------------\n",
      "firstSoftmax.shape => \n",
      " (5,)\n",
      "firstSoftmax => \n",
      " [0.4 0.  0.5 0.4 0.4]\n",
      "zeroIndex => \n",
      " [[0 2 3]]\n",
      "number of model inputs => 1\n",
      "valueCopy => \n",
      " [[0.4]\n",
      " [0.5]\n",
      " [0.4]]\n",
      "modelMatrix => \n",
      " [[0.7 0.6 1.  0.7 0.7]\n",
      " [1.1 1.  0.6 1.  0.7]\n",
      " [1.2 1.3 0.9 1.2 0.5]]\n",
      "modelMatrix.shape => \n",
      " (3, 5)\n",
      "indexs => \n",
      " [[3 3 3]\n",
      " [0 1 3]]\n",
      "------------- step 1 -------------\n",
      "number of model inputs => 2\n",
      "valueCopy => \n",
      " [[1.2]\n",
      " [1.3]\n",
      " [1.2]]\n",
      "modelMatrix => \n",
      " [[1.7 1.3 1.6 1.3 1.3]\n",
      " [1.9 1.5 1.4 1.5 1.6]\n",
      " [1.7 1.4 1.8 1.7 1.7]]\n",
      "modelMatrix.shape => \n",
      " (3, 5)\n",
      "indexs => \n",
      " [[3 3 3]\n",
      " [0 1 3]\n",
      " [0 0 2]]\n",
      "------------- step 2 -------------\n",
      "number of model inputs => 3\n",
      "valueCopy => \n",
      " [[1.7]\n",
      " [1.9]\n",
      " [1.8]]\n",
      "modelMatrix => \n",
      " [[2.1 2.5 2.3 1.9 2.4]\n",
      " [2.9 2.4 2.8 2.2 2.5]\n",
      " [2.2 2.2 2.6 2.3 2.8]]\n",
      "modelMatrix.shape => \n",
      " (3, 5)\n",
      "indexs => \n",
      " [[3 3 3]\n",
      " [1 1 3]\n",
      " [0 0 2]\n",
      " [0 2 4]]\n",
      "------------- step 3 -------------\n",
      "number of model inputs => 4\n",
      "valueCopy => \n",
      " [[2.9]\n",
      " [2.8]\n",
      " [2.8]]\n",
      "modelMatrix => \n",
      " [[3.4 3.  3.3 3.8 3.3]\n",
      " [2.8 3.  2.9 3.8 3.8]\n",
      " [3.6 3.4 3.6 3.  3.1]]\n",
      "modelMatrix.shape => \n",
      " (3, 5)\n",
      "indexs => \n",
      " [[3 3 3]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [0 2 2]\n",
      " [3 3 4]]\n",
      "------------- step 4 -------------\n",
      "number of model inputs => 5\n",
      "valueCopy => \n",
      " [[3.8]\n",
      " [3.8]\n",
      " [3.8]]\n",
      "modelMatrix => \n",
      " [[4.3 4.2 3.8 4.8 4.2]\n",
      " [4.3 4.1 4.1 4.2 4.6]\n",
      " [4.5 4.2 3.8 4.6 4.1]]\n",
      "modelMatrix.shape => \n",
      " (3, 5)\n",
      "indexs => \n",
      " [[3 3 3]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [0 2 2]\n",
      " [3 3 4]\n",
      " [3 4 3]]\n",
      "------------- step 5 -------------\n",
      "number of model inputs => 6\n",
      "valueCopy => \n",
      " [[4.8]\n",
      " [4.6]\n",
      " [4.6]]\n",
      "modelMatrix => \n",
      " [[5.4 4.8 5.5 5.2 5.3]\n",
      " [5.  5.  5.2 5.6 4.7]\n",
      " [4.9 4.6 5.3 5.3 4.8]]\n",
      "modelMatrix.shape => \n",
      " (3, 5)\n",
      "indexs => \n",
      " [[3 3 3]\n",
      " [1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 2]\n",
      " [3 3 3]\n",
      " [3 3 4]\n",
      " [0 2 3]]\n",
      "values=> \n",
      " [[[0.4       ]\n",
      "  [0.5       ]\n",
      "  [0.4       ]]\n",
      "\n",
      " [[0.73868665]\n",
      "  [0.80024387]\n",
      "  [0.73868665]]\n",
      "\n",
      " [[0.7878872 ]\n",
      "  [0.88057981]\n",
      "  [0.8342335 ]]\n",
      "\n",
      " [[1.09889451]\n",
      "  [1.0610016 ]\n",
      "  [1.0610016 ]]\n",
      "\n",
      " [[1.23169901]\n",
      "  [1.23169901]\n",
      "  [1.23169901]]\n",
      "\n",
      " [[1.36941589]\n",
      "  [1.31235689]\n",
      "  [1.31235689]]\n",
      "\n",
      " [[1.54059287]\n",
      "  [1.56912237]\n",
      "  [1.59765187]]]\n",
      "finalValue => \n",
      " [[5.4]\n",
      " [5.5]\n",
      " [5.6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, 2, 3, 4, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "n_values = 5\n",
    "np.random.seed(seed=2)\n",
    "#l1------------------------------------\n",
    "a = np.random.rand(n_values).round(1)\n",
    "#l2------------------------------------\n",
    "a10 = np.random.rand(n_values).round(1)\n",
    "a20 = np.random.rand(n_values).round(1)\n",
    "a30 = np.random.rand(n_values).round(1)\n",
    "#l3------------------------------------\n",
    "a11 = np.random.rand(n_values).round(1)\n",
    "a21 = np.random.rand(n_values).round(1)\n",
    "a31 = np.random.rand(n_values).round(1)\n",
    "#l4------------------------------------\n",
    "a12 = np.random.rand(n_values).round(1)\n",
    "a22 = np.random.rand(n_values).round(1)\n",
    "a32 = np.random.rand(n_values).round(1)\n",
    "#l5------------------------------------\n",
    "a13 = np.random.rand(n_values).round(1)\n",
    "a23 = np.random.rand(n_values).round(1)\n",
    "a33 = np.random.rand(n_values).round(1)\n",
    "#l6------------------------------------\n",
    "a14 = np.random.rand(n_values).round(1)\n",
    "a24 = np.random.rand(n_values).round(1)\n",
    "a34 = np.random.rand(n_values).round(1)\n",
    "#l7-------------------------------------\n",
    "a15 = np.random.rand(n_values).round(1)\n",
    "a25 = np.random.rand(n_values).round(1)\n",
    "a35 = np.random.rand(n_values).round(1)\n",
    "#l7-------------------------------------\n",
    "a16 = np.random.rand(n_values).round(1)\n",
    "a26 = np.random.rand(n_values).round(1)\n",
    "a36 = np.random.rand(n_values).round(1)\n",
    "#---------------------------------------\n",
    "mat0 = np.stack((a10,a20,a30))\n",
    "mat1 = np.stack((a11,a21,a31))\n",
    "mat2 = np.stack((a12,a22,a32))\n",
    "mat3 = np.stack((a13,a23,a33))\n",
    "mat4 = np.stack((a14,a24,a34))\n",
    "mat5 = np.stack((a15,a25,a35))\n",
    "mat6 = np.stack((a16,a26,a36))\n",
    "mat = np.stack((mat0,mat1,mat2,mat3,mat4,mat5,mat6))\n",
    "#----------------------------------------------------------------\n",
    "#in this part we assume that we feed our X's to our model and thats time for generating\n",
    "# Function parameters\n",
    "show = True\n",
    "Ty = 6\n",
    "epsilonType = '64'\n",
    "indexs = 0\n",
    "models = models\n",
    "mat = mat\n",
    "#----------------------------------------------------------------\n",
    "lastA = None # no need to use this in test\n",
    "lastC = None # no need to use this in test\n",
    "#----------------------------------------------------------------\n",
    "autoBeamSequence = beamSearchTest(mat ,a, lastA , lastA, models, Ty)\n",
    "autoBeamSequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diagram of beam search test on specified value ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/beam_test.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And original beamSearch() ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------\n",
    "n_values = 293\n",
    "#------------------------------------------\n",
    "xInit = np.expand_dims(testX[:,0,:],axis = 1) #(m,Tx,n_values) (1, 1, 293)\n",
    "aInit = np.zeros((1,32))                      #(1,n) (1, 32)\n",
    "cInit = np.zeros((1,32))                      #(1,n) (1, 32)\n",
    "#----------------------------------------------------------------\n",
    "#in this part we assume that we feed our X's to our model and thats time for generating\n",
    "# Function parameters\n",
    "show = True\n",
    "Ty = 6\n",
    "epsilonType = '64'\n",
    "indexs = 0\n",
    "lastSoftmax = models[1].predict([xInit,aInit,cInit])\n",
    "lastA = np.zeros((3,32))                      #(beam_width,n) (3, 32) processed hidden state from last model\n",
    "lastC = np.zeros((3,32))                      #(beam_width,n) (3, 32) processed hidden cell from last model\n",
    "models = models\n",
    "#----------------------------------------------------------------\n",
    "sequence = beamSearch(lastSoftmax, lastA, lastC, models, Ty,show=False)\n",
    "sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dont worry if you just saw all `zeros` vactor ... that's because of weak learning. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 4, 293), (None, 32), (None, 32)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[4].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 293)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = (np.stack((testX[:,1,:])))\n",
    "temp.shape\n",
    "np.zeros((1,293)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((1,4,293))\n",
    "a = np.zeros((1,32))  #(m,n_values) (1, 32)\n",
    "c = np.zeros((1,32))  #(m,n_values) (1, 32)\n",
    "#----------------------------------------------------\n",
    "numberOfInputs = x.shape[1]\n",
    "model = models[numberOfInputs]\n",
    "lastSoftmax = model.predict([x,a,c])\n",
    "lastA = np.zeros((3,32))                      #(beam_width,n) (3, 32) processed hidden state from last model\n",
    "lastC = np.zeros((3,32))                      #(beam_width,n) (3, 32) processed hidden cell from last model\n",
    "#lastSoftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape => [(None, 3, 293), (None, 32), (None, 32)]\n",
      "output_shape => (None, 293)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "input3ModelPred.shape => (2, 293)\n"
     ]
    }
   ],
   "source": [
    "temp = np.squeeze(np.stack((testX[:,1,:],testX[:,1,:])))\n",
    "testX3 = np.stack((temp,temp,temp),axis = 1) #(m,Tx,n_values) (2, 3, 293)\n",
    "testA3 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "testC3 = np.zeros((2,32))  #(m,n_values) (2, 32)\n",
    "#model\n",
    "input3Model = models[3]\n",
    "print('input_shape =>',input3Model.input_shape)\n",
    "print('output_shape =>',input3Model.output_shape)\n",
    "input3ModelPred = input3Model.predict([testX3,testA3,testC3])\n",
    "#print('input3ModelPred =>',np.array(input3ModelPred))\n",
    "print('input3ModelPred.shape =>',np.array(input3ModelPred).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiInputHiddenCellSequenceInferenceModel(LSTM_cell, densor,Ty,Tx):\n",
    "    \"\"\"\n",
    "    Uses the trained \"LSTM_cell\" and \"densor\" from model() to generate a sequence of values.\n",
    "\n",
    "    Arguments:\n",
    "    LSTM_cell -- the trained \"LSTM_cell\" from model(), Keras layer object\n",
    "    densor -- the trained \"densor\" from model(), Keras layer object\n",
    "    Ty -- integer, number of time steps to generate\n",
    "    sequence -- sequence of works you have done so far in that day\n",
    "\n",
    "    Returns:\n",
    "    inference_model -- Keras model instance\n",
    "    \"\"\"\n",
    "    # Get the shape of input values\n",
    "    n_values = densor.units\n",
    "    # Get the number of the hidden state vector\n",
    "    n_a = LSTM_cell.units\n",
    "\n",
    "    # Define the input of your model with a shape \n",
    "    X = Input(shape=(Tx, n_values),name='X') #(None, Tx, n_values)\n",
    "\n",
    "    # Tx of current sequence in other hand number of works you have done so far in that day\n",
    "    # Define s0, initial hidden state for the decoder LSTM\n",
    "    a0 = Input(shape=(n_a,), name='a0') #init\n",
    "    c0 = Input(shape=(n_a,), name='c0') #init\n",
    "    a = a0 \n",
    "    c = c0 \n",
    "    \n",
    "    #no need to save generated outputs we just need last a ,c and x\n",
    "    for t in range(Tx):\n",
    "        #Select the \"t\"th time step vector from X. \n",
    "        x = X[:,t,:] #(None, n_values)\n",
    "        #Use reshaper to reshape x to be (1, n_values)\n",
    "        x = reshaper(x) #(None, 1, n_values)\n",
    "        #Perform one step of the LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a,c])\n",
    "        #Apply densor to the hidden state output of LSTM_Cell\n",
    "        out = densor(a)\n",
    "\n",
    "    # So now we have new a, c\n",
    "    x = tf.math.argmax(out,-1)\n",
    "    x = tf.one_hot(x,n_values)\n",
    "    # Use RepeatVector(1) to convert x into a tensor with shape=(None, 1, 90)\n",
    "    x = RepeatVector(1)(x)\n",
    "\n",
    "    #Create an empty list of \"outputs\" to later store your predicted values \n",
    "    outputs = []\n",
    "    #Loop over Ty and generate a value at every time step\n",
    "    for t in range(Ty):\n",
    "        #Perform one step of LSTM_cell\n",
    "        a, _, c = LSTM_cell(inputs=x, initial_state=[a,c])\n",
    "        #Apply Dense layer to the hidden state output of the LSTM_cell\n",
    "        out = densor(a)\n",
    "        #Append the prediction \"out\" to \"outputs\". out.shape = (None, 90)\n",
    "        outputs.append(out)\n",
    "        # Select the next value according to \"out\",\n",
    "        # Set \"x\" to be the one-hot representation of the selected value\n",
    "        x = tf.math.argmax(out,-1)\n",
    "        x = tf.one_hot(x,n_values)\n",
    "        #RepeatVector(1) to convert x into a tensor with shape=(None, 1, 90)\n",
    "        x = RepeatVector(1)(x)\n",
    "        \n",
    "    #model instance with the correct \"inputs\" and \"outputs\"\n",
    "    inference_model = Model(inputs = [X,a0,c0] , outputs = [outputs,a,c])\n",
    "    \n",
    "    \n",
    "    return inference_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenCellModel = multiInputHiddenCellSequenceInferenceModel(LSTM_cell, densor, Ty = 1,Tx = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenCellModels = [0]\n",
    "for nOfInputs in range(1,5):\n",
    "    hiddenCellModels.append(multiInputHiddenCellSequenceInferenceModel(LSTM_cell, densor, Ty = 1,Tx = nOfInputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyAndStack(array,beamWidth):\n",
    "    matrix = np.zeros((beamWidth,array.shape[-1]))\n",
    "    arange = np.arange(0,beamWidth)\n",
    "    matrix[arange,:] = array.copy()\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequenceGenerator(currentSequence,hiddenCellModels = hiddenCellModels ,beamWidth = 3,models = models):\n",
    "    #----------------------------------------------------\n",
    "    initA = np.zeros((1,32))  #init values (m,n_values) (1, 32) \n",
    "    initC = np.zeros((1,32))  #init values (m,n_values) (1, 32)\n",
    "    #----------------------------------------------------\n",
    "    numberOfInputs = currentSequence.shape[1]\n",
    "    model = hiddenCellModels[numberOfInputs]\n",
    "    lastSoftmax,lastA,lastC = model.predict([currentSequence,initA,initC])\n",
    "    #----------------------------------------------------\n",
    "    print(lastA.shape)\n",
    "    lastA = copyAndStack(lastA,beamWidth)\n",
    "    lastC = copyAndStack(lastC,beamWidth)\n",
    "    lastSoftmax = np.squeeze(np.array(lastSoftmax),axis=0)\n",
    "    #----------------------------------------------------\n",
    "    sequence = beamSearch(lastSoftmax, lastA, lastC, models, Ty_max=8,show=False)\n",
    "    #----------------------------------------------------\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "(1, 32)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentSequence = np.zeros((1,4,293)) # what have you done so far...\n",
    "sequenceGenerator(currentSequence,hiddenCellModels = hiddenCellModels ,beamWidth = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "When obtaining a predicted y^ that is bad, one can wonder why we did not get a good prediction y*\n",
    "by performing the following error analysis:\n",
    "\n",
    "![Alt text](images/error%20analysis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
